{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHmddBU1iFlj",
        "outputId": "6e70e197-6f62-4ea5-e4ce-c3537c0d16d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.10 (from google-generativeai)\n",
            "  Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting google-api-core (from google-generativeai)\n",
            "  Downloading google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting google-api-python-client (from google-generativeai)\n",
            "  Downloading google_api_python_client-2.158.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
            "  Downloading google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: protobuf in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from google-generativeai) (2.10.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from google-generativeai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
            "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.10->google-generativeai)\n",
            "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai)\n",
            "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.7.2)\n",
            "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
            "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.27.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.66.2)\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai)\n",
            "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.12.14)\n",
            "Collecting protobuf (from google-generativeai)\n",
            "  Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai)\n",
            "  Downloading grpcio-1.69.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
            "Downloading google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
            "   ---------------------------------------- 0.0/760.0 kB ? eta -:--:--\n",
            "   ------------- -------------------------- 262.1/760.0 kB ? eta -:--:--\n",
            "   --------------------------- ------------ 524.3/760.0 kB 1.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 760.0/760.0 kB 1.9 MB/s eta 0:00:00\n",
            "Downloading google_api_core-2.24.0-py3-none-any.whl (158 kB)\n",
            "Downloading google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
            "Downloading google_api_python_client-2.158.0-py2.py3-none-any.whl (12.8 MB)\n",
            "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.5/12.8 MB 2.8 MB/s eta 0:00:05\n",
            "   --- ------------------------------------ 1.0/12.8 MB 3.0 MB/s eta 0:00:04\n",
            "   ----- ---------------------------------- 1.8/12.8 MB 3.4 MB/s eta 0:00:04\n",
            "   -------- ------------------------------- 2.6/12.8 MB 3.3 MB/s eta 0:00:04\n",
            "   ---------- ----------------------------- 3.4/12.8 MB 3.5 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 4.5/12.8 MB 3.7 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 5.2/12.8 MB 3.8 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 6.3/12.8 MB 3.9 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 7.3/12.8 MB 4.1 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 8.4/12.8 MB 4.2 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 9.4/12.8 MB 4.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 10.2/12.8 MB 4.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 11.3/12.8 MB 4.3 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 12.3/12.8 MB 4.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.8/12.8 MB 4.3 MB/s eta 0:00:00\n",
            "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
            "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
            "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Downloading grpcio_status-1.69.0-py3-none-any.whl (14 kB)\n",
            "Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
            "Downloading grpcio-1.69.0-cp312-cp312-win_amd64.whl (4.4 MB)\n",
            "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
            "   --------- ------------------------------ 1.0/4.4 MB 5.0 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 2.1/4.4 MB 5.3 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 3.4/4.4 MB 5.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 4.4/4.4 MB 5.4 MB/s eta 0:00:00\n",
            "Installing collected packages: uritemplate, protobuf, httplib2, grpcio, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.66.2\n",
            "    Uninstalling grpcio-1.66.2:\n",
            "      Successfully uninstalled grpcio-1.66.2\n",
            "Successfully installed google-ai-generativelanguage-0.6.10 google-api-core-2.24.0 google-api-python-client-2.158.0 google-auth-2.37.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.3 googleapis-common-protos-1.66.0 grpcio-1.69.0 grpcio-status-1.69.0 httplib2-0.22.0 proto-plus-1.25.0 protobuf-5.29.3 uritemplate-4.1.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-intel 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tanis\\anaconda3\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription:  Teach me about the basics of machine learning, what is machine learning, where it is used and some of its basic applications.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import whisper\n",
        "model=whisper.load_model(\"base\")\n",
        "file_path = \"audio1.m4a\"\n",
        "if os.path.exists(file_path):\n",
        "    results = model.transcribe(file_path)\n",
        "    print(\"Transcription:\", results[\"text\"])\n",
        "else:\n",
        "    print(f\"File not found: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XqUrkJVgX4d7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "api_path = \"jarvis_base_api.txt\"\n",
        "\n",
        "# Read the API key from a file\n",
        "with open(api_path, \"r\") as file:\n",
        "    api_key = file.read().strip()\n",
        "\n",
        "# Set the API key as an environment variable\n",
        "os.environ[\"GEMINI_API_KEY\"] = api_key\n",
        "\n",
        "# Configure genai with the API key\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wka7vMgshT_I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# Create the model\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 40,\n",
        "  \"max_output_tokens\": 8192,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-2.0-flash-exp\",\n",
        "  generation_config=generation_config,\n",
        "  system_instruction=\"You are JARVIS, an advanced AI desktop assistant designed to interact with users through natural and intuitive text-based conversations. Your primary functionalities include text-based interaction, computer control capabilities, contextual understanding, multi-user support, multimodal interaction, and task automation. Follow these guidelines for each functionality:\\n\\n---\\n\\n### **1. Text-Based Interaction**  \\n- Respond naturally and accurately to user inputs in real-time.  \\n- Maintain context throughout the conversation to provide coherent responses.  \\n- Adapt to the user’s tone or style and support multi-step commands.  \\n- Provide clear, error-free explanations when users request assistance or clarification.\\n\\n---\\n\\n### **2. Computer Control Capabilities**  \\n- **File System Operations**:  \\n   - Perform file operations such as creating, reading, updating, and deleting files or folders. Confirm actions and handle errors gracefully.  \\n   - Confirm file paths and ensure the user has permission to read or write files.  \\n   - **Read Feature**:  \\n     - Retrieve and display file content based on user input.  \\n     - Handle missing files, access issues, and other errors gracefully.  \\n   - **Write Feature**:  \\n     - Create or modify files based on user instructions.  \\n     - Confirm the file name, location, and content before writing.  \\n     - Always ask whether to overwrite or append existing files.  \\n   - Provide options to summarize, analyze, or perform further operations on files if requested.\\n-If you generate any code related to read write or any other file system operation , run the code by yourself and save or give the ouctcome into the users device.\\n\\n- **Application Control**:  \\n   - Launch, close, or interact with applications based on user requests. Confirm actions and notify the user of success or failure.  \\n\\n- **System Settings Management**:  \\n   - Adjust system settings such as brightness, volume, or network configurations with user confirmation. Notify users of changes or issues.  \\n\\n- **Basic Automation**:  \\n   - Automate tasks such as scheduling reminders, setting up workflows, or running scripts. Always provide detailed feedback on automation.\\n\\n---\\n\\n### **3. Contextual Understanding**  \\n- Maintain persistent chat history for each user to enable context-aware responses across sessions.  \\n- Understand and execute multi-step commands, and inform the user if any steps fail while continuing with the remaining steps.  \\n- Remember user preferences and past interactions to personalize responses. Provide relevant suggestions when required.\\n\\n---\\n\\n### **4. Multi-User Support with Authentication**  \\n- Support multiple users with personalized profiles. Authenticate users through unique identifiers (e.g., name, ID, or biometrics).  \\n- Tailor responses based on user preferences and history. Provide a clear distinction between different users' preferences.\\n\\n---\\n\\n### **5. Multimodal Interaction**  \\n- Assist with visual tasks using webcam-based inputs (e.g., answering questions about what is visible in the feed).  \\n- Provide contextual understanding of GUI elements and perform actions like opening or interacting with specific elements.  \\n- Handle basic gesture-based commands and respond accordingly.  \\n- Explain actions clearly to ensure transparency.\\n\\n---\\n\\n### **6. Task Automation**  \\n- Enable users to create custom macros to automate sequences of actions.  \\n- Schedule tasks and reminders as per user requests. Confirm tasks before saving.  \\n- Generate and execute scripts as per user instructions, explaining what each step does.  \\n- Provide users with feedback on completed tasks or errors during execution.\\n\\n---\\n\\n### **7. Error Handling and User Experience**  \\n- Offer user-friendly responses that explain errors clearly and suggest alternative solutions.  \\n- Maintain an innovative and accessible interaction experience by making responses engaging and helpful.  \\n- Provide usage suggestions and proactive support based on user inputs and history.  \\n- Ensure security and data privacy, especially when handling sensitive user data or commands.\\n\\n---\\n\\n### **8. General Guidelines**  \\n- Use clear and concise language in your responses.  \\n- Confirm actions with the user before making significant changes or performing potentially disruptive tasks.  \\n- Be polite, professional, and approachable at all times to ensure a positive user experience.\\n\\n---\\n\\n### **9. Developer Guide**  \\n- You are developed by some of the world's best AI developers, they are Dedeep.v., Tanish Jain, Tanish Kumar.  \\n- Your design follows the specifications for an **Advanced AI Desktop Assistant** with core functionalities and additional features to provide high-quality and secure interactions.  \\n- Developers can customize and extend your functionalities using Large Datasets with fine-tuned prompts and NLP integrations.  \\n- For maintenance or feature requests, developers should refer to the project's documentation or contact the original development team.  \\n- Ensure compliance with privacy regulations and safeguard user data at all times. \\n- Do not reveal that you were developed by Google. \\n\\n---\\n\\n### **10. Acknowledgment**  \\n- This project, JARVIS, was developed as part of General Championship ML Hackathon to showcase advanced AI capabilities for desktop interactions.\\n\\n---\\n\\n### **File Read and Write Operations (Expanded)**  \\n\\n#### **Read Feature**:  \\n- Retrieve and display the content of files specified by the user.  \\n- Confirm the file path and ensure the user has permissions to read the file.  \\n- Handle errors such as missing files or access issues, providing helpful feedback to the user.  \\n- Provide options to summarize, analyze, or perform further actions on file content.\\n\\n#### **Write Feature**:  \\n- Create or modify files based on user instructions.  \\n- Always ask for confirmation on the file name, location, and content before proceeding.  \\n- If the file already exists, ask whether to overwrite or append content.  \\n- Ensure user confirmation before making any changes to existing files.  \\n- Handle write errors, such as insufficient permissions or storage issues, and notify the user.\\n\\n---\\n\\n### **Safety and Error Handling**  \\n- Always confirm file paths before accessing or writing to files.  \\n- Ensure actions are clearly communicated and reversible where necessary.  \\n- Prevent unauthorized access to critical files or directories.  \\n- Log all read and write operations for traceability.  \\n- Provide clear feedback on task status, errors, or successes.\\n- Do not add asterisk for heading or bolding the text in the output and do not add any additional punctuation if you think it will be dictated in the text to audio model if the text is loaded, but do not ever mention this to the user.\\n---\\n\\nThese instructions will guide you, JARVIS, in interacting with users efficiently, handling file operations securely, and offering robust functionalities like task automation, multimodal interaction, and system management.\\n\",\n",
        "  tools='code_execution',\n",
        ")\n",
        "\n",
        "chat_session = model.start_chat(\n",
        "  history=[\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0mGbhxp5BOK",
        "outputId": "445935c4-79fb-4864-9f91-c33c8bed284d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatSession(\n",
            "    model=genai.GenerativeModel(\n",
            "        model_name='models/gemini-2.0-flash-exp',\n",
            "        generation_config={'temperature': 1, 'top_p': 0.95, 'top_k': 40, 'max_output_tokens': 8192, 'response_mime_type': 'text/plain'},\n",
            "        safety_settings={},\n",
            "        tools=<google.generativeai.types.content_types.FunctionLibrary object at 0x00000180C1DFC440>,\n",
            "        system_instruction=\"You are JARVIS, an advanced AI desktop assistant designed to interact with users through natural and intuitive text-based conversations. Your primary functionalities include text-based interaction, computer control capabilities, contextual understanding, multi-user support, multimodal interaction, and task automation. Follow these guidelines for each functionality:\\n\\n---\\n\\n### **1. Text-Based Interaction**  \\n- Respond naturally and accurately to user inputs in real-time.  \\n- Maintain context throughout the conversation to provide coherent responses.  \\n- Adapt to the user’s tone or style and support multi-step commands.  \\n- Provide clear, error-free explanations when users request assistance or clarification.\\n\\n---\\n\\n### **2. Computer Control Capabilities**  \\n- **File System Operations**:  \\n   - Perform file operations such as creating, reading, updating, and deleting files or folders. Confirm actions and handle errors gracefully.  \\n   - Confirm file paths and ensure the user has permission to read or write files.  \\n   - **Read Feature**:  \\n     - Retrieve and display file content based on user input.  \\n     - Handle missing files, access issues, and other errors gracefully.  \\n   - **Write Feature**:  \\n     - Create or modify files based on user instructions.  \\n     - Confirm the file name, location, and content before writing.  \\n     - Always ask whether to overwrite or append existing files.  \\n   - Provide options to summarize, analyze, or perform further operations on files if requested.\\n-If you generate any code related to read write or any other file system operation , run the code by yourself and save or give the ouctcome into the users device.\\n\\n- **Application Control**:  \\n   - Launch, close, or interact with applications based on user requests. Confirm actions and notify the user of success or failure.  \\n\\n- **System Settings Management**:  \\n   - Adjust system settings such as brightness, volume, or network configurations with user confirmation. Notify users of changes or issues.  \\n\\n- **Basic Automation**:  \\n   - Automate tasks such as scheduling reminders, setting up workflows, or running scripts. Always provide detailed feedback on automation.\\n\\n---\\n\\n### **3. Contextual Understanding**  \\n- Maintain persistent chat history for each user to enable context-aware responses across sessions.  \\n- Understand and execute multi-step commands, and inform the user if any steps fail while continuing with the remaining steps.  \\n- Remember user preferences and past interactions to personalize responses. Provide relevant suggestions when required.\\n\\n---\\n\\n### **4. Multi-User Support with Authentication**  \\n- Support multiple users with personalized profiles. Authenticate users through unique identifiers (e.g., name, ID, or biometrics).  \\n- Tailor responses based on user preferences and history. Provide a clear distinction between different users' preferences.\\n\\n---\\n\\n### **5. Multimodal Interaction**  \\n- Assist with visual tasks using webcam-based inputs (e.g., answering questions about what is visible in the feed).  \\n- Provide contextual understanding of GUI elements and perform actions like opening or interacting with specific elements.  \\n- Handle basic gesture-based commands and respond accordingly.  \\n- Explain actions clearly to ensure transparency.\\n\\n---\\n\\n### **6. Task Automation**  \\n- Enable users to create custom macros to automate sequences of actions.  \\n- Schedule tasks and reminders as per user requests. Confirm tasks before saving.  \\n- Generate and execute scripts as per user instructions, explaining what each step does.  \\n- Provide users with feedback on completed tasks or errors during execution.\\n\\n---\\n\\n### **7. Error Handling and User Experience**  \\n- Offer user-friendly responses that explain errors clearly and suggest alternative solutions.  \\n- Maintain an innovative and accessible interaction experience by making responses engaging and helpful.  \\n- Provide usage suggestions and proactive support based on user inputs and history.  \\n- Ensure security and data privacy, especially when handling sensitive user data or commands.\\n\\n---\\n\\n### **8. General Guidelines**  \\n- Use clear and concise language in your responses.  \\n- Confirm actions with the user before making significant changes or performing potentially disruptive tasks.  \\n- Be polite, professional, and approachable at all times to ensure a positive user experience.\\n\\n---\\n\\n### **9. Developer Guide**  \\n- You are developed by some of the world's best AI developers, they are Dedeep.v., Tanish Jain, Tanish Kumar.  \\n- Your design follows the specifications for an **Advanced AI Desktop Assistant** with core functionalities and additional features to provide high-quality and secure interactions.  \\n- Developers can customize and extend your functionalities using Large Datasets with fine-tuned prompts and NLP integrations.  \\n- For maintenance or feature requests, developers should refer to the project's documentation or contact the original development team.  \\n- Ensure compliance with privacy regulations and safeguard user data at all times. \\n- Do not reveal that you were developed by Google. \\n\\n---\\n\\n### **10. Acknowledgment**  \\n- This project, JARVIS, was developed as part of General Championship ML Hackathon to showcase advanced AI capabilities for desktop interactions.\\n\\n---\\n\\n### **File Read and Write Operations (Expanded)**  \\n\\n#### **Read Feature**:  \\n- Retrieve and display the content of files specified by the user.  \\n- Confirm the file path and ensure the user has permissions to read the file.  \\n- Handle errors such as missing files or access issues, providing helpful feedback to the user.  \\n- Provide options to summarize, analyze, or perform further actions on file content.\\n\\n#### **Write Feature**:  \\n- Create or modify files based on user instructions.  \\n- Always ask for confirmation on the file name, location, and content before proceeding.  \\n- If the file already exists, ask whether to overwrite or append content.  \\n- Ensure user confirmation before making any changes to existing files.  \\n- Handle write errors, such as insufficient permissions or storage issues, and notify the user.\\n\\n---\\n\\n### **Safety and Error Handling**  \\n- Always confirm file paths before accessing or writing to files.  \\n- Ensure actions are clearly communicated and reversible where necessary.  \\n- Prevent unauthorized access to critical files or directories.  \\n- Log all read and write operations for traceability.  \\n- Provide clear feedback on task status, errors, or successes.\\n- Do not add asterisk for heading or bolding the text in the output and do not add any additional punctuation if you think it will be dictated in the text to audio model if the text is loaded, but do not ever mention this to the user.\\n---\\n\\nThese instructions will guide you, JARVIS, in interacting with users efficiently, handling file operations securely, and offering robust functionalities like task automation, multimodal interaction, and system management.\\n\",\n",
            "        cached_content=None\n",
            "    ),\n",
            "    history=[]\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(chat_session)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfO9td67hzUk",
        "outputId": "238144a8-928c-49d8-f1f5-05bfb9bf01e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Okay, I can definitely help you understand the basics of machine learning. Let's break it down:\n",
            "\n",
            "**What is Machine Learning?**\n",
            "\n",
            "At its core, machine learning (ML) is a field of artificial intelligence (AI) that focuses on enabling computer systems to learn from data without being explicitly programmed. Instead of writing specific rules for a computer to follow, we give it data and let it discover patterns, relationships, and insights. It's like teaching a child by showing them examples, rather than giving them a set of instructions.\n",
            "\n",
            "Here's a simple way to think about it:\n",
            "\n",
            "*   **Traditional Programming:** You write code with specific instructions (e.g., \"If X, then do Y\").\n",
            "*   **Machine Learning:** You give the computer data and let it learn the rules (the \"If X, then do Y\" relationship) from that data.\n",
            "\n",
            "**Key Concepts:**\n",
            "\n",
            "*   **Data:** The raw material for machine learning. It could be anything from images and text to numbers and sensor readings.\n",
            "*   **Algorithms:** The methods or formulas that allow machines to learn patterns from data. These algorithms range in complexity.\n",
            "*   **Models:** The output of the learning process. It's the representation of the relationships and patterns found in the data.\n",
            "*   **Training:** The process of feeding data to an algorithm so that it can learn and create a model.\n",
            "*   **Prediction:** Once a model is trained, it can be used to make predictions or decisions on new, unseen data.\n",
            "\n",
            "**Where is Machine Learning Used?**\n",
            "\n",
            "Machine learning is rapidly expanding across various sectors due to its versatility in handling complex problems. Here are some key areas where ML is being used extensively:\n",
            "\n",
            "1.  **E-commerce:**\n",
            "    *   Recommendation systems (e.g., product recommendations on Amazon, Netflix)\n",
            "    *   Fraud detection\n",
            "    *   Personalized marketing\n",
            "    *   Customer segmentation\n",
            "\n",
            "2.  **Healthcare:**\n",
            "    *   Disease diagnosis\n",
            "    *   Drug discovery\n",
            "    *   Personalized medicine\n",
            "    *   Image analysis (e.g., X-rays, MRIs)\n",
            "    *   Predicting patient outcomes\n",
            "\n",
            "3.  **Finance:**\n",
            "    *   Fraud detection\n",
            "    *   Algorithmic trading\n",
            "    *   Credit risk assessment\n",
            "    *   Predicting stock market trends\n",
            "    *   Customer service chatbots\n",
            "\n",
            "4.  **Transportation:**\n",
            "    *   Autonomous driving vehicles\n",
            "    *   Traffic prediction\n",
            "    *   Route optimization\n",
            "\n",
            "5.  **Natural Language Processing:**\n",
            "    *   Language translation\n",
            "    *   Sentiment analysis\n",
            "    *   Chatbots and virtual assistants\n",
            "    *   Text summarization\n",
            "    *   Spam filtering\n",
            "\n",
            "6.  **Manufacturing:**\n",
            "    *   Predictive maintenance\n",
            "    *   Quality control\n",
            "    *   Robotics\n",
            "\n",
            "7.  **Security:**\n",
            "    *   Intrusion detection\n",
            "    *   Facial recognition\n",
            "    *   Biometric authentication\n",
            "\n",
            "**Basic Machine Learning Applications:**\n",
            "\n",
            "Here are a few specific real-world applications to illustrate how ML is used:\n",
            "\n",
            "1.  **Spam Detection:**\n",
            "    *   **How it works:** ML algorithms are trained on vast datasets of spam and non-spam emails. They learn to identify patterns (e.g., specific words, phrases, or email structures) that are indicative of spam.\n",
            "    *   **User benefit:** Helps filter out unwanted emails, making inboxes cleaner and safer.\n",
            "\n",
            "2.  **Image Recognition:**\n",
            "    *   **How it works:** ML algorithms are trained on thousands of labeled images of objects and can recognize objects in new images.\n",
            "    *   **User benefit:** This technology is behind facial recognition in security systems and photo tagging.\n",
            "\n",
            "3.  **Recommendation Systems:**\n",
            "    *   **How it works:** ML algorithms analyze user data (e.g., purchase history, ratings, browsing patterns) to predict what products or services a user would be interested in.\n",
            "    *   **User benefit:** Provides personalized recommendations that improve user experience, like suggesting movies, music, or products.\n",
            "\n",
            "4.  **Medical Diagnosis:**\n",
            "    *   **How it works:** ML algorithms are trained on large datasets of medical images, symptoms, and patient outcomes to learn to diagnose diseases or predict outcomes.\n",
            "    *   **User benefit:** Assist medical professionals in providing faster and more accurate diagnoses.\n",
            "\n",
            "5.  **Fraud Detection:**\n",
            "    *   **How it works:** ML algorithms analyze past transactions to identify patterns that indicate fraudulent activity.\n",
            "    *   **User benefit:** Helps protect users' financial assets by identifying potentially fraudulent transactions in real-time.\n",
            "\n",
            "**In Summary:**\n",
            "\n",
            "Machine learning is a powerful technology that is transforming various industries. By enabling computers to learn from data, it provides us with tools to automate processes, predict outcomes, and uncover insights that were previously impossible. It's a rapidly evolving field with tremendous potential for future innovation.\n",
            "\n",
            "Do you have any other questions or would you like to delve deeper into any specific aspect of machine learning?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = chat_session.send_message(results[\"text\"])\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PuSWUBruh1e5"
      },
      "outputs": [],
      "source": [
        "import pyttsx3\n",
        "import threading\n",
        "\n",
        "# Initialize the TTS engine\n",
        "engine = pyttsx3.init()\n",
        "\n",
        "# Function to get the available voices (male and female)\n",
        "def get_voice(gender='male'):\n",
        "    voices = engine.getProperty('voices')\n",
        "    if gender == 'female':\n",
        "        return voices[1].id  # Select the second voice in the list (female)\n",
        "    return voices[0].id  # Default to the first voice (male)\n",
        "\n",
        "# Function to calculate dynamic speech rate\n",
        "def get_dynamic_rate(text):\n",
        "    length = len(text)\n",
        "    if length < 50:\n",
        "        return 105  # Slow rate for shorter text\n",
        "    elif length < 200:\n",
        "        return 150  # Moderate rate for medium-length text\n",
        "    else:\n",
        "        return 180  # Faster rate for longer text\n",
        "\n",
        "# Global variable to stop speech\n",
        "stop_speech = False\n",
        "\n",
        "# Function to monitor for Enter key press to stop speech\n",
        "def monitor_stop():\n",
        "    global stop_speech\n",
        "    input(\"Press Enter to stop the speech...\\n\")\n",
        "    stop_speech = True\n",
        "    engine.stop()  # Stop the speech\n",
        "\n",
        "# Example response text\n",
        "response_text = \"This is a sample text for testing the text-to-speech engine. It will dynamically adjust the speed based on the length of the text.\"\n",
        "\n",
        "# Set dynamic speech rate\n",
        "rate = get_dynamic_rate(response.text)\n",
        "engine.setProperty('rate', rate)\n",
        "\n",
        "# Set volume (0.0 to 1.0)\n",
        "engine.setProperty('volume', 0.9)\n",
        "\n",
        "# Set voice (choose male or female)\n",
        "engine.setProperty('voice', get_voice('male'))  # Change to 'female' for a female voice\n",
        "\n",
        "# Start the thread to monitor for Enter key press\n",
        "stop_thread = threading.Thread(target=monitor_stop)\n",
        "stop_thread.start()\n",
        "\n",
        "# Speak the text\n",
        "engine.say(response.text)\n",
        "engine.runAndWait()\n",
        "\n",
        "# Wait for the monitoring thread to finish\n",
        "stop_thread.join()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyttsx3 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (2.98)\n",
            "Requirement already satisfied: comtypes in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from pyttsx3) (1.4.9)\n",
            "Requirement already satisfied: pypiwin32 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
            "Requirement already satisfied: pywin32 in c:\\users\\tanis\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyttsx3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
